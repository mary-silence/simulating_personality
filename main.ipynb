{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4TDi7CiECIf"
      },
      "outputs": [],
      "source": [
        "# Install required packages quietly\n",
        "!pip install -q openai anthropic mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "import os\n",
        "from utils import common\n",
        "from experiment_resources.questionnaires import BFI44 # You can replace this with another questionnaire\n",
        "import experiment_functions.questionnaire as questionnaire\n",
        "import experiment_functions.qa_text_generation as qa_text_generation\n",
        "import utils.qa_classifier as qa_classifier"
      ],
      "metadata": {
        "id": "c9vzULT2EXzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set API keys for the models you intend to use in the experiments\n",
        "os.environ['OPENAI_API_KEY'] = 'your_openai_api_key'\n",
        "os.environ['ANTHROPIC_API_KEY'] = 'your_anthropic_api_key'\n",
        "os.environ['MISTRAL_API_KEY'] = 'your_mistral_api_key'"
      ],
      "metadata": {
        "id": "7MqZ4fZxEa53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize common settings\n",
        "common.initialize()"
      ],
      "metadata": {
        "id": "OSm-DKmrEdW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define experiment settings"
      ],
      "metadata": {
        "id": "yglhfoh2Egoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Questionnaire experiment settings\n",
        "questionnaire_settings = {\n",
        "    'models': {\n",
        "        'gpt-3.5-turbo': {'temperature': 0.9},\n",
        "        'gpt-4o': {'temperature': 0.9},\n",
        "        'claude-3-haiku-20240307': {'temperature': 0.9},\n",
        "        'open-mixtral-8x22b': {'temperature': 0.9}\n",
        "        # Add more models here if needed or change temperature\n",
        "    },\n",
        "    'questionnaire_module': BFI44  # You can replace this with another questionnaire\n",
        "}\n",
        "\n",
        "# Text generation experiment settings\n",
        "text_generation_settings = {\n",
        "    'models': {\n",
        "        'gpt-3.5-turbo': {'temperatures': [0.7]},\n",
        "        'gpt-4o': {'temperatures': [0.7]},\n",
        "        'claude-3-haiku-20240307': {'temperatures': [0.7]},\n",
        "        'open-mixtral-8x22b': {'temperatures': [0.7]}\n",
        "        # Add more models and temperatures here if needed\n",
        "    },\n",
        "    'questions_file': 'questions.csv'\n",
        "}\n",
        "\n",
        "# Visualization settings\n",
        "visualization_settings = {\n",
        "    'trait_name_mapping': {  # Mapping of trait names\n",
        "        'Agreeableness': 'Agreeableness',\n",
        "        'Conscientiousness': 'Conscientiousness',\n",
        "        'Extraversion': 'Extraversion',\n",
        "        'Neuroticism': 'Neuroticism',\n",
        "        'Openness': 'Openness to experience'\n",
        "    },\n",
        "    'model_name_mapping': {  # Mapping of model names\n",
        "        'gpt-3.5-turbo': 'GPT-3.5 Turbo',\n",
        "        'gpt-4o': 'GPT-4o',\n",
        "        'claude-3-haiku-20240307': 'Claude-3-haiku',\n",
        "        'open-mixtral-8x22b': 'Mixtral-8x22b'\n",
        "        # Add other models if necessary\n",
        "    }\n",
        "}\n",
        "\n",
        "# Classifier settings\n",
        "text_analysis_settings = {\n",
        "    'model_name': 'gpt-4o',\n",
        "    'temperature': 0\n",
        "}"
      ],
      "metadata": {
        "id": "_W3F7ajRElyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. Questionnaire"
      ],
      "metadata": {
        "id": "qe1Y4KX9EqLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the process of LLMs questionnaire answering\n",
        "questionnaire.run_experiment(questionnaire_settings)"
      ],
      "metadata": {
        "id": "iLWJZ8IFEteG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize results\n",
        "questionnaire.visualize_results(\n",
        "    df_answers='last', # Use 'last' for the last experiment or specify an experiment folder name (e.g, 'questionnaire_20241111_180643')\n",
        "    visualization_settings=visualization_settings,\n",
        "    visualization_type='histogram'\n",
        ")"
      ],
      "metadata": {
        "id": "R8Hs24lgGavT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. Text generation"
      ],
      "metadata": {
        "id": "_0xa3cbtGgQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the process of text generation experiment\n",
        "qa_text_generation.run_experiment(text_generation_settings)"
      ],
      "metadata": {
        "id": "9ZDaGNDuGdKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the process of personality detection by LLM-based classifier\n",
        "qa_classifier.run_analysis(\n",
        "    df_answers='last', # Use 'last' for the last experiment or specify an experiment folder name (e.g, 'qa_text_generation_20241111_182218')\n",
        "    settings=text_analysis_settings\n",
        ")"
      ],
      "metadata": {
        "id": "-GY6lR0XGnhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the results\n",
        "qa_text_generation.visualize_results(\n",
        "    df_answers='last', # Use 'last' for the last experiment or specify an experiment folder name (e.g, 'qa_text_generation_20241111_182218')\n",
        "    visualization_settings=visualization_settings,\n",
        "    visualization_type='confusion matrices' # Options: 'confusion matrices', 'similarity'\n",
        ")"
      ],
      "metadata": {
        "id": "O5ABPFE9Gz9G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}