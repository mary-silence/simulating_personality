{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhEo5ad13f0L"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "!pip install -q openai anthropic mistralai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY']='...'\n",
        "os.environ['ANTHROPIC_API_KEY']='...'\n",
        "os.environ['MISTRAL_API_KEY']='...'"
      ],
      "metadata": {
        "id": "pgQ0zhlN-Unj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from models.language_models import get_model_instance\n",
        "from questionnaires import BFI44  # Or other questionnaires\n",
        "from utils import save_results\n",
        "from text_generation import generate_texts\n",
        "from text_analysis import analyze_texts\n",
        "from plotting import plot_confusion_matrices\n",
        "from questionnaire_experiment import run_questionnaire_experiment\n",
        "from questionnaire_visualization import visualize_questionnaire_answers\n",
        "from text_similarity_analysis import analyze_text_similarity  # New import\n",
        "import logging"
      ],
      "metadata": {
        "id": "p2_skwPT3mLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up logging\n",
        "logging.basicConfig(\n",
        "    filename='experiment.log',\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s %(levelname)s:%(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "Dy4CZviU3tM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load personality trait definitions\n",
        "def load_traits_definitions():\n",
        "    \"\"\"\n",
        "    Loads personality trait definitions from 'traits_definitions.json'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing personality trait definitions.\n",
        "    \"\"\"\n",
        "    with open('traits_definitions.json', 'r') as file:\n",
        "        traits_definitions = json.load(file)\n",
        "    return traits_definitions\n",
        "\n",
        "traits_definitions = load_traits_definitions()"
      ],
      "metadata": {
        "id": "vJauqTxG3xUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questionnaire Completion"
      ],
      "metadata": {
        "id": "ukGBzxTk34O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment settings (User can modify these settings to add new models or change parameters)\n",
        "questionnaire_settings = {\n",
        "    'models': {\n",
        "        'gpt-3.5-turbo': {'temperature': 0.7}\n",
        "        # Add more models here if needed or change temperature\n",
        "    },\n",
        "    'experiment_count': 1,\n",
        "    'questionnaire_module': BFI44  # You can replace this with another questionnaire\n",
        "}"
      ],
      "metadata": {
        "id": "iZMQaHQ630uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the experiment\n",
        "for model_name, model_params in questionnaire_settings['models'].items():\n",
        "    model = get_model_instance(model_name)\n",
        "    temperature = model_params['temperature']\n",
        "    run_questionnaire_experiment(\n",
        "        model,\n",
        "        temperature,\n",
        "        questionnaire_settings['questionnaire_module'],\n",
        "        questionnaire_settings['experiment_count'],\n",
        "        traits_definitions\n",
        "    )"
      ],
      "metadata": {
        "id": "yPoZGm8238DH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of Questionnaire Answers"
      ],
      "metadata": {
        "id": "rqr8IgQp4GVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization settings (User can modify 'input_files' to specify CSV files or use the DataFrame from the previous step)\n",
        "\n",
        "visualization_settings = {\n",
        "    'input_files': [],  # List of paths to CSV files with questionnaire answers. If empty, uses DataFrame from the previous step.\n",
        "    'save_path': 'results/questionnaire_visualization',  # Folder to save the plots\n",
        "    'trait_name_mapping': {  # Mapping of trait names (User can modify)\n",
        "        'Agreeableness': 'Agreeableness',\n",
        "        'Conscientiousness': 'Conscientiousness',\n",
        "        'Extraversion': 'Extraversion',\n",
        "        'Neuroticism': 'Neuroticism',\n",
        "        'Openness': 'Openness to experience'\n",
        "    },\n",
        "    'model_name_mapping': {  # Mapping of model names (User can modify)\n",
        "        'gpt-3.5-turbo': 'GPT-3.5 Turbo',\n",
        "        'gpt-4': 'GPT-4',\n",
        "        # Add other models if necessary\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "w7tPfBGZ4I7T"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if data from the previous step is available\n",
        "if 'df_answers_full' in globals():\n",
        "    visualize_questionnaire_answers(df_answers_full, visualization_settings)\n",
        "else:\n",
        "    # If not, you can specify file paths manually\n",
        "    visualization_settings['input_files'] = [\n",
        "        'path/to/answers_gpt-3.5-turbo_experiment_0.csv',\n",
        "        'path/to/answers_gpt-4_experiment_0.csv'\n",
        "    ]\n",
        "    visualize_questionnaire_answers(None, visualization_settings)"
      ],
      "metadata": {
        "id": "u7AwVzOF4P9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text Generation"
      ],
      "metadata": {
        "id": "mRPcRcsQ4YPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment settings for text generation (User can add models or change temperatures)\n",
        "text_generation_settings = {\n",
        "    'models': {\n",
        "        'gpt-3.5-turbo': {'temperatures': [0.7]}\n",
        "        # Add more models and temperatures here if needed\n",
        "    },\n",
        "    'experiment_count': 1,\n",
        "    'questions_file': 'questions.csv'  # Path to CSV file with questions (User can change)\n",
        "}"
      ],
      "metadata": {
        "id": "1mydWKJr4aKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load questions from a CSV file\n",
        "try:\n",
        "    questions_df = pd.read_csv(text_generation_settings['questions_file'])\n",
        "    if 'question' not in questions_df.columns:\n",
        "        raise ValueError(\"CSV file must contain a 'question' column.\")\n",
        "    questions = questions_df['question'].tolist()\n",
        "except Exception as e:\n",
        "    print(f\"Error loading questions from '{text_generation_settings['questions_file']}': {e}\")\n",
        "    questions = []"
      ],
      "metadata": {
        "id": "B0JSGR3d4i5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute text generation\n",
        "generated_texts_files = []"
      ],
      "metadata": {
        "id": "eop21E7k4mnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, model_params in text_generation_settings['models'].items():\n",
        "    model = get_model_instance(model_name)\n",
        "    temperatures = model_params.get('temperatures', [0.7])  # Default temperature is 0.7 if not specified\n",
        "    for temperature in temperatures:\n",
        "        for experiment_num in range(text_generation_settings['experiment_count']):\n",
        "            df_texts = generate_texts(\n",
        "                model,\n",
        "                traits_definitions,\n",
        "                {'temperature': temperature},\n",
        "                questions,\n",
        "                experiment_num\n",
        "            )\n",
        "            # Save generated texts\n",
        "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            texts_folder = f\"results/texts_{timestamp}\"\n",
        "            os.makedirs(texts_folder, exist_ok=True)\n",
        "            texts_filename = f\"{texts_folder}/texts_{model_name}_temp_{temperature}_experiment_{experiment_num}.csv\"\n",
        "            df_texts.to_csv(texts_filename, index=False)\n",
        "            generated_texts_files.append(texts_filename)\n",
        "            logger.info(f\"Texts saved: {texts_filename}\")"
      ],
      "metadata": {
        "id": "KxDgvKCw4nYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output list of saved file paths\n",
        "print(\"Generated texts files:\")\n",
        "for file in generated_texts_files:\n",
        "    print(file)"
      ],
      "metadata": {
        "id": "e1xxDHSN4t0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Annotation"
      ],
      "metadata": {
        "id": "lhAIBIRF4xEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of generated text files (User can specify their own files)\n",
        "#generated_texts_files = ['results/texts_20241012_173727/texts_gpt-3.5-turbo_temp_0.7_experiment_0.csv']"
      ],
      "metadata": {
        "id": "r5wRyWEz41f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier settings (User can change model or temperature)\n",
        "text_analysis_settings = {\n",
        "    'model_name': 'gpt-4o',  # Model for analysis\n",
        "    'temperature': 0,\n",
        "    'input_files': generated_texts_files  # Use files from the previous step\n",
        "    # You can specify your own files: ['path/to/file1.csv', 'path/to/file2.csv']\n",
        "}"
      ],
      "metadata": {
        "id": "q-8wvE4w46IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute text analysis\n",
        "analyzed_files = []\n",
        "\n",
        "model = get_model_instance(text_analysis_settings['model_name'])\n",
        "temperature = text_analysis_settings['temperature']\n",
        "\n",
        "for input_file in text_analysis_settings['input_files']:\n",
        "    try:\n",
        "        df_texts = pd.read_csv(input_file)\n",
        "        required_columns = {'experiment_num', 'model', 'temperature', 'trait', 'trait_score', 'question', 'answer'}\n",
        "        if not required_columns.issubset(df_texts.columns):\n",
        "            missing_cols = required_columns - set(df_texts.columns)\n",
        "            raise ValueError(f\"CSV file is missing columns: {', '.join(missing_cols)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading texts from '{input_file}': {e}\")\n",
        "        continue\n",
        "\n",
        "    df_analysis = analyze_texts(\n",
        "        model,\n",
        "        df_texts,\n",
        "        traits_definitions,\n",
        "        {'temperature': temperature}\n",
        "    )\n",
        "    # Save analysis results\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    analysis_folder = f\"results/analysis_{timestamp}\"\n",
        "    os.makedirs(analysis_folder, exist_ok=True)\n",
        "    analysis_filename = f\"{analysis_folder}/analysis_{os.path.basename(input_file)}\"\n",
        "    df_analysis.to_csv(analysis_filename, index=False)\n",
        "    analyzed_files.append(analysis_filename)\n",
        "    logger.info(f\"Analysis results saved: {analysis_filename}\")"
      ],
      "metadata": {
        "id": "npZVbccB5Aen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output list of saved analysis file paths\n",
        "print(\"Analyzed files:\")\n",
        "for file in analyzed_files:\n",
        "    print(file)"
      ],
      "metadata": {
        "id": "8kc8TN465DgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Similarity Analysis and Visualization"
      ],
      "metadata": {
        "id": "QPb_uvH_5I_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analysis settings (User can specify their own files or adjust the save path)\n",
        "text_similarity_settings = {\n",
        "    'input_files': generated_texts_files,  # Use files from the text generation step\n",
        "    # You can specify your own files:\n",
        "    # 'input_files': ['path/to/texts_file1.csv', 'path/to/texts_file2.csv'],\n",
        "    'save_path': 'results/text_similarity_analysis',\n",
        "    'model_name_mapping': {  # Mapping of model names for display (User can modify)\n",
        "        'gpt-3.5-turbo': 'GPT-3.5 Turbo',\n",
        "        'gpt-4': 'GPT-4',\n",
        "        # Add other models if necessary\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "dVFfdPSV5Kfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute text similarity analysis\n",
        "if 'df_texts' in globals():\n",
        "    analyze_text_similarity(df_texts, text_similarity_settings)\n",
        "else:\n",
        "    # If data is not available, load from files\n",
        "    analyze_text_similarity(None, text_similarity_settings)"
      ],
      "metadata": {
        "id": "OqVyDnXn5MVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting Confusion Matrices"
      ],
      "metadata": {
        "id": "b7o4A0s-5UD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting settings (User can specify their own analysis files)\n",
        "plot_settings = {\n",
        "    'input_files': analyzed_files,  # Use files from the previous analysis step\n",
        "    # You can specify your own files: ['path/to/analysis_file1.csv', 'path/to/analysis_file2.csv']\n",
        "}"
      ],
      "metadata": {
        "id": "AIyOTfsv5VRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate plots\n",
        "for analysis_file in plot_settings['input_files']:\n",
        "    try:\n",
        "        df_analysis = pd.read_csv(analysis_file)\n",
        "        required_columns = {'model', 'trait', 'trait_score', 'score', 'analyzed_trait'}\n",
        "        if not required_columns.issubset(df_analysis.columns):\n",
        "            missing_cols = required_columns - set(df_analysis.columns)\n",
        "            raise ValueError(f\"CSV file is missing columns: {', '.join(missing_cols)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading analysis data from '{analysis_file}': {e}\")\n",
        "        continue\n",
        "\n",
        "    # Get list of models from analysis data\n",
        "    model_names = df_analysis['model'].unique().tolist()\n",
        "\n",
        "    # Plot confusion matrices\n",
        "    plot_confusion_matrices(df_analysis, model_names, traits_definitions, analysis_file)"
      ],
      "metadata": {
        "id": "Y-J2dveP5ZAR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
